from generate import StreamDataGenerator
from itertools import islice
import datetime
import json

import psycopg2

g = StreamDataGenerator()
docs = g.parse()

connection = psycopg2.connect(user="postgres", password="pass", host="127.0.0.1", port="15432", database="pages")
cursor = connection.cursor()
cursor.execute("DROP TABLE IF EXISTS pages;")
cursor.execute("DROP INDEX IF EXISTS pages_abstract;")
cursor.execute("DROP INDEX IF EXISTS pages_title;")
connection.commit()
cursor.execute("CREATE TABLE pages(id BIGINT PRIMARY KEY GENERATED BY DEFAULT AS IDENTITY, title TEXT NOT NULL, abstract TEXT NOT NULL, url TEXT NOT NULL);")
connection.commit()

i = 1

seconds = 0.0
try:
  batch_data = []
  for d in docs:
    i += 1
    d["id"] = i
    batch_data.append(cursor.mogrify("(%s, %s, %s)", (d["abstract"], d["title"], d["url"])).decode("utf-8"))

    if i % 100 == 0:
      begin = datetime.datetime.now()
      args_str = ','.join(batch_data)
      cursor.execute("INSERT INTO pages (abstract, title, url) VALUES " + args_str) 

      td = (datetime.datetime.now() - begin)
      seconds += td.seconds + td.microseconds * 0.000001
      batch_data = []

    if i % 100000 == 0:
      begin = datetime.datetime.now()
      connection.commit()
      td = (datetime.datetime.now() - begin)
      seconds += td.seconds + td.microseconds * 0.000001
      
      print("Batch %s" % i)
finally:
  
  begin = datetime.datetime.now()
  cursor.execute("CREATE INDEX pages_idx ON pages USING GIN ((setweight(to_tsvector('english'::regconfig, title), 'A') || setweight(to_tsvector('english'::regconfig, abstract), 'B')));")
  connection.commit()

  td = (datetime.datetime.now() - begin)
  seconds += td.seconds + td.microseconds * 0.000001
  print("Indexed %s docs in %s seconds" % (i, seconds))
  print("%s docs per second" % (float(i) / seconds))